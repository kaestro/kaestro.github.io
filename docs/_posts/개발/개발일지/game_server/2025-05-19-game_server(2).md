---
layout: series
classes: wide
title: "비동기 및 멀티 스레드 에코 서버 개발"
subtitle: ""
date: 2025-05-19
categories: "개발일지"
published: true
recommended: true
series: "Game Server Development"
seriesIndex: 2
---

우선은 1단계 목표로 삼았던 기초적인 멀티 스레드 에코 서버를 개발할 수 있었고, 이 과정에
대한 회고를 남깁니다. 내용은 다음의 단계로 구성됩니다.

```
1. 개발 진행 과정
2. 비동기화
3. 멀티 스레드화
```

### 개발 진행 과정

멀티 스레드 에코 서버 개발을 진행한 과정은 다음을 거쳤습니다.

우선 싱글스레드 동기적 에코 서버를 하나의 server.cpp에 아무 것도 분리하지 않은 상태로
구현합니다. 이 때, 개발하는 서버가 점진적으로 발전할 것이기 때문에 여러 형태의 서버를
유연하게 대응할 수 있도록 별도의 IClientHandler라는 인터페이스를 생성해두고, 서버는
이를 이용하는 방식으로 구현합니다. 이 때의 에코 서버는 단순함을 확보하기 위해 단일
연결에 대한 요청을 수행한 경우 종료되도록 했습니다.

이후에 클라이언트 핸들러와 서버 클래스 자체를 구분하고, 헤더와 소스코드를 구분하는 과정을
위해 프로젝트에 기초적인 구조(src, include)와 CmakeLists.txt를 통해 빌드 시스템을
구축합니다.

그 다음으로는 에코 서버의 성능을 조금 더 구체화합니다. 서버는 이제 단일 요청을 수행하더라도
다음 요청을 수행하기 위해 열려있는 상태로 대기합니다. 대신 한 요청에서 유저가 악성으로,
혹은 부주의로 연결을 한 뒤 메시지를 보내는 등의 요청을 수행하지 않는 경우에 대해 처리하기
위해 타임아웃을 설정해두었습니다.

그 다음으로는 서버가 비동기적으로 동작하도록 변경하였습니다. 이 과정에서 제가 기존에
생각했던 public handle_client 함수보다는 run_server_loop을 두고, 이에 각각의 핸들러 별로
상세 구현에 필요한 private function들을 따로 두는 것이 낫다는 생각을 하게 돼 IclientHandler와
server 클래스의 구조를 변경하는 작업을 했습니다.

이전에는 server에서 Handler를 생성한 뒤 handle_client를 호출해 서버 내부적에서
클라이언트에 대한 핸들링 자체를 직접 했다면, 이제 server객체는 단순히 client에 대한
flag를 받으면 해당 객체를 initialize하고, run_server_loop, shutdown을 수행하는 형태로
기능이 단순화 및 추상화되었습니다.

---

### 비동기화

최초에는 boost의 asio 라이브러리를 사용하는 것을 생각했습니다만, 이를 이용하기에는
생각보다 제 c++ 언어 자체의 숙련도 자체도 모자라다는 점과 해당 라이브러리를 사용하는
것이 네트워크에 대한 기본적인 이해를 높이려는 프로젝트의 목적에 부합하지 못하다는
생각을 하게 됐습니다.

이 때문에 stl의 std::async를 사용하는 것과 epoll을 사용하는 것 중에 epoll을 사용하는
쪽을 선택했습니다. std::async를 사용하는 것이 더 비동기 자체에 대한 이해를 높이는
데에 도움이 됐겠지만, 그 정도의 저수준 구현을 하기 위해서는 2단계로 잡아둔 프로토콜에
대한 이해가 선행하는 것이 맞다는 판단을 했기 때문입니다. 이 때문에 epoll을 통해 비동기
프로그램이 동작하는 방식에 대해 이해하고, 추후에 필요하다면 std::async를 이용한 별도의
async echo client handler 등을 구현해 볼 생각입니다.

비동기 프로그래밍을 이해하기 위한 여정에서 epoll은 중요한 역할을 합니다. 전통적인 I/O
모델에서는 여러 클라이언트의 연결을 처리하기 위해 각 연결마다 스레드를 생성하거나,
select나 poll과 같은 시스템 호출을 사용하여 이벤트 발생 여부를 확인해야 했습니다.
poll은 파일 디스크립터 목록을 순회하며 이벤트가 발생했는지 확인하는 방식으로 동작합니다.
하지만 연결 수가 많아질수록 불필요한 순회 작업이 증가하여 성능 저하를 야기할 수 있습니다.

epoll은 이러한 poll의 단점을 개선하기 위해 등장한 Linux 시스템의 I/O 이벤트 통지 메커니즘입니다.
epoll은 관심 있는 파일 디스크립터를 등록해두고, 이벤트가 발생한 파일 디스크립터만을 반환하는
방식으로 동작합니다. 이를 통해 불필요한 순회를 줄이고, 많은 수의 연결을 효율적으로 처리할
수 있습니다. 특히 네트워크 프로그래밍에서 epoll은 서버가 동시에 여러 클라이언트의 요청을
비동기적으로 처리하는 데 필수적인 요소로 활용됩니다. 이벤트 기반의 비동기 프로그래밍 모델을
구현하는 데 핵심적인 역할을 수행하며, 높은 성능과 확장성을 갖춘 서버 애플리케이션을 구축하는
데 기여합니다.

제가 구현한 AsyncEchoClientHandler에서는 서버가 시작되면 epoll을 하나 생성합니다. 이
때  epoll은 서버 소켓을 감시대상으로 두고, 서버 소켓에서 읽을 준비가 됐을 때 이벤트가
발생한 파일 디스크럽터와 해당 이벤트 정보를 events 배열에 저장합니다.

이제 추가적인 연결이 발생하면 서버는 accept()를 통해 클라이언트 별로 새로운 소켓을 할당하고,
이 소켓을 비블로킹 모드로 설정한 후 이벤트 발생을 epoll을 통해 비동기적으로 감지할 수
있도록 등록합니다. epoll_wait()는 등록된 소켓에서 이벤트가 발생할 때까지 대기하며,
이벤트가 감지될 경우 해당 소켓의 읽기 가능(EPOLLIN) 또는 쓰기 가능(EPOLLOUT) 여부에
따라 handle_client_read() 또는 handle_client_write() 함수를 호출하여 네트워크 데이터를
읽어 내부 버퍼에 저장하거나, 버퍼의 데이터를 소켓을 통해 네트워크로 전송합니다. 이때 각
클라이언트의 상태(예: 송수신 버퍼)는 client_states_ 맵을 통해 관리됩니다.

이러한 이벤트들의 핸들링 자체는 메인 스레드의 while 루프에서 epoll_wait()를 통해 이벤트들을
계속해서 감시하고, 감지된 이벤트에 따라 적절한 동작(데이터 읽기, 쓰기, 연결 종료 등)을
수행하는 방식으로 이루어집니다. 오류 발생 시에는 perror()를 통해 오류를 보고하고,
remove_client_from_epoll()을 호출하여 해당 클라이언트 연결을 종료합니다.
