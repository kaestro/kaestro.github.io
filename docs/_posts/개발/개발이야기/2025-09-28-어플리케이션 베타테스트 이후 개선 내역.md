---
layout: 산문
classes: wide
title: "어플리케이션 베타테스트 이후 개선 내역"
date: 2025-09-28
categories: "개발이야기"
---

## 서론

이번에 회사에 디자인 팀이 추가되며 기존의 직접 개발을 하는 개발자 외에 QA를 하는 과정이 새로
더해졌고, 도움을 받아 추가로 유저들에게 베타 테스트를 진행할 수 있었습니다. 덕분에 개발자들끼리는
확인할 수 없었던 여러 서버의 문제점들을 발견할 수 있었고 이에 대해 진행한 대응들에 대해 정리
하려 합니다.

발견 가능했던 여러 문제점들에는 메모리 누수에 따른 서버 응답 실패 및 과도한 인스턴스 추가 발생,
로깅 시스템의 구조적 설계 및 로그 레벨 구분 설정 미비, 기획 변경에 따라가지 못했던 알고리즘
조정 등이 있습니다.

---

## 메모리 누수로 인한 서버 응답 실패 및 인스턴스 증가 대응

### 인프라 측면에서의 해소

이번에 내부에서 소규모로 개발팀이 llm에 쿼리를 보내고 응답을 보냈을 때와 달리, 실제 환경에서
응답이 계속해서 실패하고 빈 결과 값만을 사용자에게 내보내고 있는 결과가 관측됐습니다. 처음에는
gemini api 자체의 응답 실패 혹은 빈 응답이 발생하는 것이 문제가 아닐까하고 생각했습니다. 저희
쪽 서버에서는 빈 응답이 오고 있다고 로그를 찍어 내보내고 있었고 gemini api가 실패한 응답을
제대로 처리해주지 않는다는 커뮤니티의 의견도 발견할 수 있었거든요. 하지만 그와 별개로 빈 응답이
발생하는 케이스가 너무 다발적이었고 개발 환경에서보다 비교적 높은 트래픽을 처리하는 과정에서
해당 이슈가 발생할 가장 높은 원인은 메모리라 판단했고 이와 관련한 대응을 하기 위해 일종의
스트레스 테스트를 진행하기로 결정했습니다. 서버의 메모리 용량 차지하는 것이 약 50%에서 머물고
있는데 cloudrun에서 인스턴스 갯수가 늘어난다는 것도 고려사항 중 하나였습니다.

스트레스 테스트는 단순하게 파이썬 스크립트를 이용해 저희 내부 api 중 gemini api server에
요청을 보내는 것을 골라 동시에 10 x (1, 2, 3, 4, 5, 10)의 쿼리를 날려보는 식으로 이 때
다양한 형태의 질문 및 컨텍스트를 변경해가는 것을 통해 진행했습니다. 그리고 50개의 요청을 보낼때부터
5% 이내의 요청이 실패하기 시작하며, 100개의 요청을 보낼 때는 사실상 대부분에 해당하는 약
50%의 요청이 실패하는 것을 관측할 수 있었습니다. 그리고 해당 시점에 메모리 사용량이 거의
100%에 도달하는 것을 확인할 수 있었기 때문에 메모리 이슈가 맞다는 판단 하에 인프라에서 기존의
500mb였던 메모리 크기를 cloudrun의 인스턴스 당 메모리 상한인 2GB로 대증적인 해결을 해뒀습니다.

### 메모리 누수 개선

그와 별개로, 50개 혹은 100개에 해당하는 응답을 동시에 받는다고 하더라도 llm이 응답값으로
보내는 결과 값은 그래봐야 텍스트에 불과하기 때문에 커봤자 수십 kb를 넘기지 못했습니다. 일반적으로는
10kb 내외면 큰 응답에 속했습니다. 그렇다면 1mb 밖에 안되는 응답 값을 추가로 저장하는 데에
서버의 메모리 용량이 부하를 견디지 못하고 있다는 이야기이기 때문에 말이 되지 않아 서버에서
메모리가 새고 있다는 의심을 하게 됐습니다. 그래서 이와 관련해서 조사를 시작했고 그 주 범인으로
추측되는 것은 단연 llm과의 응답을 생성하는 모듈이었습니다.

간단하게 저희 api 서버의 llm 응답 생성 모듈의 스펙에 대해 설명하자면 llm이 내보내는 응답의
결과를 모두 기다렸다가 클라이언트에 내려보내는 것은 너무 느리기에 streaming response를
사용하고 있었습니다. 문제는 해당 streaming response를 다 내려보낸 뒤에 로그의 측면에서
해당 정보를 저장하기 위해 처리하던 기능에 있었습니다.

```python
full_text = ""
async for chunk in await gemini_client.generate_content_stream():
    if hasattr(chunk, "text") and chunk.text:
        full_text += chunk.text
        yield chunk.text
```

파이썬에 익숙하신 분들이라면 위의 코드가 가져올 끔찍한 사태에 대해 예상하실 수 있을 것이라
생각합니다. 파이썬의 str 객체는 immutable이기 때문에 full_text라는 객체의 뒤에 스트링 객체에
해당하는 캐릭터를 덧붙이는 형태로 변형이 이루어지는 것이 아니라 full_text라는 호출하는 변수명만
동일한 새로운 객체가 내부에서 하나 재생성되는 메모리 누수가 발생하게 됩니다. 그리고 10kb 정도의
텍스트를 streaming 형태로 gemini api에서 처리받을 경우에 이는 최악의 경우 GB 정도에 해당하는
공간을 차지하는 재앙이 발생합니다. 자세한 내용은 다음과 같은 [real python post](https://realpython.com/python-string-concatenation/)
등을 통해 확인하실 수 있습니다.

이후에 해당 코드를 예제외 비슷하게 list and join의 형태로 변경하고 응답이 빈 형태로 나오지
않는 것을 확인할 수 있었습니다.

```python
response_list = []
async for chunk in await gemini_client.generate_content_stream():
    if hasattr(chunk, "text") and chunk.text:
        response_list.append(chunk.text)
        yield chunk.text
```

---

## 요청 추적을 위한 로깅 시스템 구조 개편

실제 유저들의 데이터를 확인하는 과정에서 지금 서버의 로깅 시스템은 개발자가 단일의 유저가
서버에 요청한 내용들에 대한 확인만을 고려했을 뿐, 실질적으로 유저가 생성하는 동시다발적인
로그들에 대해서는 대응하기에 불편한 구조로 작성됐다는 사실을 알 수 있었습니다. 이는 로그들이
모든 메소드마다 개별적으로 다 발생하고 있기 때문에 하나의 요청 처리에도 십수개씩의 로그들을
확인해야하는 경우가 잦은데 이를 묶어주는 하나의 tracdID와 같은 값이 없어 일일히 찍어가며
연속되는 로그들을 구분해야했기 때문입니다. 코드로 놓고보면 이와 같다 말할 수 있습니다.

```python
class HelloWorldController:
    def Endpoint():
        logger.info("Hello World Endpoint called!")
        self.service.execute_hello_world()
        logger.info("Hello World Endpoint execution finished")

class HelloWorldService:
    def execute_hello_world():
        logger.info("execution of hello world started")

        logger.info("querying hello started")
        self.repository.query_hello()
        logger.info("posting hello started")
        self.repository.post_hello()

        logger.info("hello world execution finished")

class HelloRepository:
    def query_hello():
        logger.info("get hello data from repository")
        try:
            result = self.db_engine.query("hello")
            logger.info("querying hello resulted in the following: ", result)
            return result
        except Exception as e:
            logger.exception(f"querying hello from {result} failed due following", e)
```

위와 같은 형태로 코드들이 작성 돼있을 경우에 실제 운영 환경에서는 다음과 같은 로그들이 발생하게 됩니다.

```
2025-09-28 14:32:15 INFO: Hello World Endpoint called!
2025-09-28 14:32:15 INFO: User Login Endpoint called!
2025-09-28 14:32:15 INFO: execution of hello world started
2025-09-28 14:32:15 INFO: validating user credentials
2025-09-28 14:32:15 INFO: querying hello started
2025-09-28 14:32:15 INFO: get hello data from repository
2025-09-28 14:32:15 INFO: get user data from repository
2025-09-28 14:32:16 INFO: querying hello resulted in the following: {'id': 1}
2025-09-28 14:32:16 INFO: user validation successful
2025-09-28 14:32:16 INFO: posting hello started
```

이 때문에 단일 요청에서도 혼란스러울 뿐더러, 동시 요청으로 들어올 경우 로그가 뒤섞여 어떤 로그가 어느
요청에 속하는지 구분할 수 없고, 에러가 발생했는데 어느 스택에서 실패했는지가 명확하지 않으며, 이에 더해
실제 운영 상황에서는 다양한 종류의 요청들이 동시에 발생하기 때문에 로그만 보고는 어떤 요청이 성공했고 실패한
경우는 어디에서 왜 실패했는지에 대한 판단이 어렵습니다.

이런 문제 때문에 gcloud의 경우에는 로깅을 위해 heading에 traceID를 사용하는 방식을 지원하나 이 변경의
규모가 작지 않다는 판단 하에 로깅 미들웨어에서 사용하기 위한 contextVar로 request_id를 설정 한 뒤에
이를 로그에 찍도록 하여 로그 탐색기에서 해당 값을 기반으로 필터링해서 보도록 했습니다. 이 작업을 하는 과정에서
기존에 프레임워크들의 로깅 시스템들이 얼마나 정교하고 많은 고민을 통해 나왔는지 알 수 있었고 다음에 로깅
시스템을 설계한다면 해당 방식으로 스택 트레이싱이 용이하도록 하고 싶다는 생각을 했네요.

이와 별개로 로그들의 레벨들이 잘못 설정 돼 정상 동작인 경우에도 error를 발생시키는 등의 문제들도 해소했
습니다.

## 과도한 권한 위임을 해소하는 응답 생성 로직 재구조화

기존의 프로그램이 동작하는 과정에서 기획이 명확하지 못했던 부분에 유연하게 대응하겠다는 목적하에 지나치게
큰 권한의 오브젝트들이 파라미터를 타고 넘어가고 있다는 사실을 확인할 수 있었고, 해당 기능들이 하위 모듈에서
불필요하게 반복적으로 사용되고 있는 부분도 동시에 발견했습니다. 예시로는 다음과 같습니다.

```python
from world_service import WorldService

class HelloService():
    def print_world(world_service: WorldService):
        print(world_service.default_doc())

    def generate_hello_world(world_service: WorldService):
        return "hello" + world_service.default_doc()

class WorldService():
    def default_doc():
        return "World"
```

이와 같은 문제는 지나친 권한이 이행되는 것을 통해 과도한 복잡성을 야기한다는 판단 하에 사용되는 의존성을
가급적 실제로 사용하는 실제의 오브젝트에 한정되도록 변경하고, 해당 과정에서 불필요한 연산이 반복적으로
이루어지는 부분을 해소했습니다.

```python
class HelloService():
    def print_world(world_text: str):
        print(world_text)
```

작업하는 과정에서 기존의 레거시 코드들이 어떤 생각으로 지금과 같은 형태들을 띨 수 있었고, 서버의 유지 및
관리 측면에서 신경써야하는 것들에는 또 무엇이 있는가 그리고 사용하는 언어 및 생태계에 대한 이해도를 꾸준히
갈고 닦을 필요가 있다는 것을 알 수 있어서 좋았습니다.

위의 작업들을 마치고 난 뒤 qa 및 베타 테스트 간에 발생한 이슈들에 대해서는 대부분 해소하는 데 성공했고
작업하기 더 좋은 환경이 됐습니다.
