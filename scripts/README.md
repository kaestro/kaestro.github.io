# AI 기반 추천 글 자동 분석 시스템

## 개요

이 시스템은 새로운 블로그 포스트가 커밋될 때 자동으로 AI를 통해 "추천 글"로 선정될 만한지 분석하고 피드백을 제공합니다.

## 시스템 구성

### 1. Post-commit Hook
- **위치**: `.git/hooks/post-commit`
- **역할**: 새로 추가된 마크다운 파일 감지 및 분석 스크립트 실행
- **트리거**: `git commit` 실행 시 자동 실행

### 2. 분석 스크립트
- **파일**: `scripts/check_recommended.sh`
- **기능**:
  - 기존 추천 글 정보 추출 (Ruby 스크립트 호출)
  - 새 포스트 메타데이터 및 내용 읽기
  - AI 프롬프트 템플릿에 변수 삽입
  - Claude CLI 실행 및 결과 출력

### 3. 추천 글 추출 스크립트
- **파일**: `scripts/extract_recommended.rb`
- **기능**:
  - 모든 포스트에서 `recommended: true` 플래그 검색
  - YAML front matter 파싱 (Date, Time 클래스 허용)
  - 제목, 카테고리, 날짜, 요약 추출
  - 마크다운 형식으로 출력

### 4. AI 프롬프트 템플릿
- **파일**: `scripts/analyze_recommended_prompt.md`
- **기능**:
  - AI에게 제공할 평가 기준 정의
  - 플레이스홀더를 통한 동적 내용 삽입
  - 응답 형식 지정

## 사용 방법

### 자동 실행
새 포스트를 추가하고 커밋하면 자동으로 분석이 실행됩니다:

```bash
git add docs/_posts/카테고리/2026-01-01-새포스트.md
git commit -m "포스트 추가"
# post-commit hook이 자동으로 AI 분석 실행
```

### 수동 실행
특정 포스트에 대해 수동으로 분석을 실행할 수 있습니다:

```bash
bash scripts/check_recommended.sh "docs/_posts/카테고리/포스트파일.md"
```

## 평가 기준

AI는 다음 6가지 기준으로 포스트를 평가합니다:

1. **독창적 통찰력**: 개인 경험에서 나온 깊은 생각이 있는가?
2. **실용적 가치**: 독자가 실제로 적용할 수 있는 조언이 있는가?
3. **구조화**: 목차와 섹션이 명확하게 구분되어 있는가?
4. **보편적 공감**: 특정 기술이 아닌 보편적 경험을 다루는가?
5. **성찰과 성장**: 문제→해결→배움의 과정이 담겨있는가?
6. **카테고리 균형**: 현재 추천글이 부족한 카테고리인가?

### 점수 기준
- **80-100점**: ✅ 강력 추천 (즉시 `recommended: true` 추가 고려)
- **60-79점**: ⚠️ 재검토 필요 (일부 개선 후 고려)
- **0-59점**: ❌ 비추천 (현재는 recommended 부적합)

## 검증 결과

### True Positive 테스트 (2026-02-01)

기존 추천 글 5개에 대해 AI 분석을 실행한 결과:

| 포스트 | 카테고리 | 점수 | 평가 |
|--------|----------|------|------|
| 어플리케이션 베타테스트 이후 개선 내역 | 개발이야기 | 78/100 | ⚠️ 재검토 필요 |
| 시스템 설계 방법 | 개발이야기 | 76/100 | ⚠️ 재검토 필요 |
| 구직을 마무리하며 | 신변잡기 | 72/100 | ⚠️ 재검토 필요 |
| 수습기간 3개월을 마무리하며 | 신변잡기 | 72/100 | ⚠️ 재검토 필요 |
| 실수가 아니었다고 | 리더십여정 | 65/100 | ⚠️ 재검토 필요 |

**평균 점수: 72.6/100**

#### 관찰 사항
1. **긍정적**:
   - 모든 추천 글이 60점 이상으로 비추천 수준은 없음
   - AI가 이미 추천 목록에 있는 글임을 정확히 인식
   - 각 글의 강점과 개선점을 구체적으로 분석

2. **개선 필요**:
   - 80점 이상의 "강력 추천"을 받은 글이 없음
   - AI가 지적한 공통 개선점:
     - 목차 부재 또는 구조화 부족
     - 오타/맞춤법 문제
     - 결론 섹션 부재
     - 정량적 결과 부족

3. **기술적 이슈**:
   - Perl 명령어에서 한글 처리 시 에러 발생 (기능에는 영향 없음)

## 기술 상세

### Git 설정
한글 파일명 정상 처리를 위해 다음 설정이 필요합니다:

```bash
git config core.quotepath false
```

### Ruby YAML 파싱
Ruby 3.4의 Psych 라이브러리 보안 기능으로 인해 `YAML.safe_load`에 허용 클래스 지정:

```ruby
YAML.safe_load($1, permitted_classes: [Date, Time])
```

### Claude CLI 사용
`--message-file` 옵션 대신 `-p` 플래그 사용:

```bash
claude -p "$(cat "$TEMP_PROMPT")"
```

## 알려진 이슈

1. **Perl 한글 처리 에러**
   - 증상: 변수 치환 시 한글 문자 관련 에러 메시지 출력
   - 영향: AI 분석 자체는 정상 작동, 에러 메시지만 표시됨
   - 상태: 기능에 영향 없어 현재는 무시

2. **중복 감지**
   - AI가 이미 추천 목록에 있는 글을 재평가할 때 중복임을 인지
   - 새 글만 평가하도록 post-commit hook에서 필터링됨

## 향후 개선 방향

1. **점수 기준 조정**
   - 현재 추천 글들의 평균 점수(72.6)를 고려한 기준 재설정
   - 65-75점 범위를 "추천 적합" 범위로 간주 가능

2. **Perl 에러 해결**
   - 한글 처리 시 발생하는 에러 메시지 제거
   - 대안: Python 스크립트로 전환 검토

3. **자동 추가 기능**
   - 80점 이상 받은 글에 대해 자동으로 `recommended: true` 추가 옵션
   - 사용자 확인 후 적용 방식 구현

4. **로그 기록**
   - 분석 결과를 파일로 저장하여 히스토리 추적
   - `.claude/recommended_analysis_log.md` 등

5. **프롬프트 개선**
   - 현재 추천 글들의 특성을 반영한 평가 기준 조정
   - 카테고리별 특성 고려

## 파일 구조

```
kaestro.github.io/
├── .git/hooks/
│   └── post-commit                        # Git hook
├── scripts/
│   ├── analyze_recommended_prompt.md      # AI 프롬프트 템플릿
│   ├── check_recommended.sh               # 메인 분석 스크립트
│   ├── extract_recommended.rb             # 추천 글 추출 스크립트
│   └── README.md                          # 본 문서
└── .pre-commit-config.yaml                # Prettier 설정
```

## 참고 자료

- [Claude CLI 문서](https://docs.anthropic.com/claude/docs)
- [Pre-commit Framework](https://pre-commit.com/)
- [Jekyll Front Matter](https://jekyllrb.com/docs/front-matter/)

---

**마지막 업데이트**: 2026-02-01
**작성자**: AI 시스템 (Claude Sonnet 4.5)
